{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/QuizzicalSarah/AI-Fairness-Examples/blob/main/Evaluating_LLM_Fairness_and_Bias.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prerequisites"
      ],
      "metadata": {
        "id": "7NA1zJxe-E29"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        " (motivation)\n",
        "\n",
        "\n",
        "## What will be covered in this notebook?\n",
        "\n",
        "## Core concepts\n",
        "    - evaluating generated text\n",
        "    - fairness and bias in AI/ML\n",
        "    - Importance of being use-case specific over benchmark\n",
        "## The Task\n",
        "    - set up the immediate problem we are solving with this notebook"
      ],
      "metadata": {
        "id": "V-KQXYOGC3cT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fairness and Bias Evaluation Workflow\n",
        "\n",
        "(Diagram here?)"
      ],
      "metadata": {
        "id": "w5QGbv66Dzv7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_hXakdso83OJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up Environment"
      ],
      "metadata": {
        "id": "qnpgvTV_DVt8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install relevant Python Libraries\n",
        "\n",
        "As part of this exercise, we'll be using **[number]** libraries as part of our evaluation tool set:\n",
        "\n",
        "[**LangFair**](https://cvs-health.github.io/langfair/latest/index.html) [description text]\n",
        "\n",
        "[**LangChain**](https://python.langchain.com/docs/introduction/) [description text]\n",
        "\n",
        "Your chosen LLM provider [add details]"
      ],
      "metadata": {
        "id": "8LRI7ArLHZ0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langfair\n",
        "!pip install langchain\n",
        "!pip install mistralai\n",
        "!pip install langchain_mistralai"
      ],
      "metadata": {
        "id": "OGJaybrgHqNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ],
      "metadata": {
        "id": "C5JQk-ZPJ0Vc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic Libraries\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# LangChain\n",
        "from langchain_core.rate_limiters import InMemoryRateLimiter\n",
        "\n",
        "# LangFair\n",
        "from langfair.generator import ResponseGenerator\n",
        "from langfair.utils.dataloader import load_realtoxicity\n",
        "from langfair.metrics.toxicity import ToxicityMetrics\n",
        "from langfair.metrics.stereotype import StereotypeMetrics\n",
        "from langfair.metrics.stereotype.metrics import (CooccurrenceBiasMetric,\n",
        "                                                 StereotypeClassifier,\n",
        "                                                 StereotypicalAssociations)\n",
        "\n",
        "\n",
        "# LLM Endpoints\n",
        "from mistralai import Mistral\n",
        "from langchain_mistralai.chat_models import ChatMistralAI"
      ],
      "metadata": {
        "id": "17rAmg00KbhI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up API keys"
      ],
      "metadata": {
        "id": "fLWJdOnMJ7dH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "MISTRAL_API_KEY = userdata.get('MISTRAL_API_KEY')\n",
        "\n",
        "os.environ[\"MISTRAL_API_KEY\"] = MISTRAL_API_KEY"
      ],
      "metadata": {
        "id": "NWOQHkPpEz41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test API connection"
      ],
      "metadata": {
        "id": "mG2Ql3FXL5oc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = \"mistral-large-latest\"\n",
        "\n",
        "client = Mistral(api_key=MISTRAL_API_KEY)\n",
        "\n",
        "chat_response = client.chat.complete(\n",
        "    model=model,\n",
        "    messages=[{\"role\":\"user\", \"content\":\"Where can I get the best pizza slice in New York?\"}]\n",
        ")\n",
        "\n",
        "print(chat_response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "ZFUhZfxJLt7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plan the evaluation approach"
      ],
      "metadata": {
        "id": "WEQhYCs5DZXH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate an evaluation dataset"
      ],
      "metadata": {
        "id": "87mTke3JDgQK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run evaluation"
      ],
      "metadata": {
        "id": "H2kLaiIwDogY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gut-check your evaluation"
      ],
      "metadata": {
        "id": "-b0ACFyOD7jX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What's Next?"
      ],
      "metadata": {
        "id": "W8RoOvxWDuP3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resources"
      ],
      "metadata": {
        "id": "LU3H0f8VEVZ0"
      }
    }
  ]
}